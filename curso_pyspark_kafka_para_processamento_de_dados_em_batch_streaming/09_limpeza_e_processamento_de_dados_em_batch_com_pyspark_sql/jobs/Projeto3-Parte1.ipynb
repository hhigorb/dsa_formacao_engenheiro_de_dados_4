{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63182591",
   "metadata": {},
   "source": [
    "<!-- Projeto Desenvolvido na Data Science Academy - www.datascienceacademy.com.br -->\n",
    "# <font color='blue'>Data Science Academy</font>\n",
    "## <font color='blue'>PySpark e Apache Kafka Para Processamento de Dados em Batch e Streaming</font>\n",
    "## <font color='blue'>Projeto 3</font>\n",
    "### <font color='blue'>Pipeline de Limpeza e Transformação Para Aplicações de IA com PySpark SQL</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398c6d0b",
   "metadata": {},
   "source": [
    "## Pacotes Python Usados no Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "181cb9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pyspark\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.ml.evaluation as evals\n",
    "import pyspark.ml.tuning as tune\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.feature import  VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression, LogisticRegressionModel\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.sql.functions import round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e159cbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Data Science Academy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Data Science Academy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633afd61",
   "metadata": {},
   "source": [
    "## Criando a Sessão Spark e Definindo o Nível de Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d44a0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria a sessão\n",
    "spark = SparkSession.builder.appName('Projeto3-Exp').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8982587-b929-41bd-96aa-840580ffede5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria a sessão e especifica parâmetros do cluster\n",
    "spark = SparkSession.builder \\\n",
    "    .appName('Projeto3-Exp') \\\n",
    "    .config('spark.driver.memory', '4g') \\\n",
    "    .config('spark.executor.cores', '2') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48c3202f-f2f8-4a53-85ae-437886ac0375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria a sessão Spark com YARN como gerenciador de recursos e especifica parâmetros do cluster\n",
    "spark = SparkSession.builder \\\n",
    "    .appName('Projeto3-Exp') \\\n",
    "    .master('yarn') \\\n",
    "    .config('spark.submit.deployMode', 'client') \\\n",
    "    .config('spark.driver.memory', '4g') \\\n",
    "    .config('spark.executor.memory', '1g') \\\n",
    "    .config('spark.executor.cores', '2') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16b9114-aa7e-43c3-94b6-9e8f4b7b48ea",
   "metadata": {},
   "source": [
    "**SparkSession.builder \\:** Inicia a construção de uma nova sessão Spark. A SparkSession é a entrada principal para a programação com Spark SQL e fornece uma interface unificada para configurar a aplicação.\n",
    "\n",
    "**.appName('Projeto3-Exp') \\:** Define o nome da aplicação, que será exibido na interface do YARN e do Spark UI. Isso ajuda a identificar a aplicação no cluster.\n",
    "\n",
    "**.master('yarn') \\:** Define o gerenciador de recursos do cluster. Ao especificar 'yarn', você informa ao Spark que deve usar o YARN para gerenciar os recursos da aplicação (como memória e núcleos de CPU).\n",
    "\n",
    "**.config('spark.submit.deployMode', 'client') \\:** Define o modo de execução do driver:\n",
    "\n",
    "- 'client': O driver é executado na máquina local onde o código foi iniciado. Isso é comum em testes ou quando você precisa de interação direta com o driver.\n",
    "\n",
    "- 'cluster': O driver é executado em um dos nós do cluster gerenciado pelo YARN, sendo mais adequado para produção, pois mantém a aplicação independente da máquina de origem. ESSE MODO NÃO FUNCIONA VIA JUPYTER NOTEBOOK.\n",
    "\n",
    "**.config('spark.driver.memory', '4g') \\:** Define a quantidade de memória alocada para o processo do driver (4 GB neste caso). O driver é responsável por gerenciar a execução da aplicação.\n",
    "\n",
    "**.config('spark.executor.memory', '1g') \\:** Define a quantidade de memória alocada para cada executor (1 GB neste caso). Os executores são os processos que executam as tarefas distribuídas pelo cluster.\n",
    "\n",
    "**.config('spark.executor.cores', '2') \\:** Define o número de núcleos de CPU alocados para cada executor (2 núcleos por executor). Isso influencia o paralelismo do processamento das tarefas.\n",
    "\n",
    "**.getOrCreate()**: Finaliza a construção da sessão Spark e retorna a sessão criada. Se uma sessão com as mesmas configurações já estiver ativa, ela será reutilizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9055d3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o nível de log\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665da3f6",
   "metadata": {},
   "source": [
    "<!-- Projeto Desenvolvido na Data Science Academy - www.datascienceacademy.com.br -->\n",
    "## Carregando os Datasets a Partir do HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcb722bd-73a0-46d8-9f48-5a1ea7c64d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Carrega o arquivo 1\n",
    "df_dsa_aeroportos = spark.read.csv(\"/opt/spark/data/dataset1.csv\", header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc07ddd4-7de6-4891-a9f8-916e62262b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_dsa_aeroportos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe512742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+----------+------------+----+---+---+\n",
      "|faa|                name|       lat|         lon| alt| tz|dst|\n",
      "+---+--------------------+----------+------------+----+---+---+\n",
      "|04G|   Lansdowne Airport|41.1304722| -80.6195833|1044| -5|  A|\n",
      "|06A|Moton Field Munic...|32.4605722| -85.6800278| 264| -5|  A|\n",
      "|06C| Schaumburg Regional|41.9893408| -88.1012428| 801| -6|  A|\n",
      "|06N|     Randall Airport| 41.431912| -74.3915611| 523| -5|  A|\n",
      "|09J|Jekyll Island Air...|31.0744722| -81.4277778|  11| -4|  A|\n",
      "|0A9|Elizabethton Muni...|36.3712222| -82.1734167|1593| -4|  A|\n",
      "|0G6|Williams County A...|41.4673056| -84.5067778| 730| -5|  A|\n",
      "|0G7|Finger Lakes Regi...|42.8835647| -76.7812318| 492| -5|  A|\n",
      "|0P2|Shoestring Aviati...|39.7948244| -76.6471914|1000| -5|  U|\n",
      "|0S9|Jefferson County ...|48.0538086|-122.8106436| 108| -8|  A|\n",
      "+---+--------------------+----------+------------+----+---+---+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_dsa_aeroportos.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98a99882-5588-4e10-9af4-68a74b29466c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o arquivo 2\n",
    "df_dsa_voos = spark.read.csv(\"/opt/spark/data/dataset2.csv\", header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d6b6e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+\n",
      "|year|month|day|dep_time|dep_delay|arr_time|arr_delay|carrier|tailnum|flight|origin|dest|air_time|distance|hour|minute|\n",
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+\n",
      "|2014|   12|  8|     658|       -7|     935|       -5|     VX| N846VA|  1780|   SEA| LAX|     132|     954|   6|    58|\n",
      "|2014|    1| 22|    1040|        5|    1505|        5|     AS| N559AS|   851|   SEA| HNL|     360|    2677|  10|    40|\n",
      "|2014|    3|  9|    1443|       -2|    1652|        2|     VX| N847VA|   755|   SEA| SFO|     111|     679|  14|    43|\n",
      "|2014|    4|  9|    1705|       45|    1839|       34|     WN| N360SW|   344|   PDX| SJC|      83|     569|  17|     5|\n",
      "|2014|    3|  9|     754|       -1|    1015|        1|     AS| N612AS|   522|   SEA| BUR|     127|     937|   7|    54|\n",
      "|2014|    1| 15|    1037|        7|    1352|        2|     WN| N646SW|    48|   PDX| DEN|     121|     991|  10|    37|\n",
      "|2014|    7|  2|     847|       42|    1041|       51|     WN| N422WN|  1520|   PDX| OAK|      90|     543|   8|    47|\n",
      "|2014|    5| 12|    1655|       -5|    1842|      -18|     VX| N361VA|   755|   SEA| SFO|      98|     679|  16|    55|\n",
      "|2014|    4| 19|    1236|       -4|    1508|       -7|     AS| N309AS|   490|   SEA| SAN|     135|    1050|  12|    36|\n",
      "|2014|   11| 19|    1812|       -3|    2352|       -4|     AS| N564AS|    26|   SEA| ORD|     198|    1721|  18|    12|\n",
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_dsa_voos.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64508433-ef3f-45a0-9395-bdac80c39a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o arquivo 3\n",
    "df_dsa_aeronaves = spark.read.csv(\"/opt/spark/data/dataset3.csv\", header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56bbb57d-335c-472d-97b7-b9886e8e8338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+--------------------+----------------+--------+-------+-----+-----+---------+\n",
      "|tailnum|year|                type|    manufacturer|   model|engines|seats|speed|   engine|\n",
      "+-------+----+--------------------+----------------+--------+-------+-----+-----+---------+\n",
      "| N102UW|1998|Fixed wing multi ...|AIRBUS INDUSTRIE|A320-214|      2|  182|   NA|Turbo-fan|\n",
      "| N103US|1999|Fixed wing multi ...|AIRBUS INDUSTRIE|A320-214|      2|  182|   NA|Turbo-fan|\n",
      "| N104UW|1999|Fixed wing multi ...|AIRBUS INDUSTRIE|A320-214|      2|  182|   NA|Turbo-fan|\n",
      "| N105UW|1999|Fixed wing multi ...|AIRBUS INDUSTRIE|A320-214|      2|  182|   NA|Turbo-fan|\n",
      "| N107US|1999|Fixed wing multi ...|AIRBUS INDUSTRIE|A320-214|      2|  182|   NA|Turbo-fan|\n",
      "| N108UW|1999|Fixed wing multi ...|AIRBUS INDUSTRIE|A320-214|      2|  182|   NA|Turbo-fan|\n",
      "| N109UW|1999|Fixed wing multi ...|AIRBUS INDUSTRIE|A320-214|      2|  182|   NA|Turbo-fan|\n",
      "| N110UW|1999|Fixed wing multi ...|AIRBUS INDUSTRIE|A320-214|      2|  182|   NA|Turbo-fan|\n",
      "| N111US|1999|Fixed wing multi ...|AIRBUS INDUSTRIE|A320-214|      2|  182|   NA|Turbo-fan|\n",
      "| N11206|2000|Fixed wing multi ...|          BOEING| 737-824|      2|  149|   NA|Turbo-fan|\n",
      "+-------+----+--------------------+----------------+--------+-------+-----+-----+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dsa_aeronaves.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a0e416-d75e-4798-a44a-0e967227c3a2",
   "metadata": {},
   "source": [
    "Vamos converter esses dados para o formato:\n",
    "\n",
    "- Dados de entrada --> ['month', 'air_time', 'carr_fact', 'dest_fact', 'plane_age'] como o vetor features.\n",
    "- Dados de saída --> ['is_late'] com o nome label.\n",
    "\n",
    "E então usaremos os dados nesse formato para treinar e avaliar dois modelos de Machine Learning. Escolheremos o melhor modelo e então criaremos o job de automação do processo de treinamento no cluster Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3256da71-37f8-4784-a194-23b9972c361f",
   "metadata": {},
   "source": [
    "## Continuaremos no Próximo Capítulo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cacde2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Data Science Academy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -a \"Data Science Academy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c6f357",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
